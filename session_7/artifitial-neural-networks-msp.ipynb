{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hossamahmedsalah/artifitial-neural-networks-msp?scriptVersionId=143601725\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"padding: 35px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://github.com/hossamAhmedSalah/Machine_Learning_MSP/blob/main/Assets/247.jpg?raw=true?)\">\n<b>\n<span style='color:skyblue'>MSP Machine Learning workshop 2023 </span>\n</b>\n<div>\n<span style='color:Salmon'>Artificial Neural Networks (ANN)</span>\n\n</div>\n\n</div>\n\n<br>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"r\">Table of content</a>\n1) [Importing the MNIST (0️⃣ .. 9️⃣) and Visualisation](#1)\n2) [Traditional Machine Learning](#2)\n    - [RandomForest with the whole dataset](#2.1)\n    - [RandomForest with the PCA reduced dim](#2.2)\n3) [ANN](#3)\n    - [Create Sequential Model](#3.1)\n    - [Add Layers](#3.2)\n    - [Compile the model](#3.3)\n    - [Train the model](#3.4)","metadata":{}},{"cell_type":"markdown","source":"# <h1 id=\"1\" style=\"color: skyblue\">Importing the MNIST (0️⃣ .. 9️⃣) and Visualisation</h1>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sns\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train \ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n# test \ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n# train sahpe and test shape\nf'train shape {train.shape}', f'test shape {test.shape}'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# spliting train to x, y\nX = train.drop(columns=['label'])\ny = train['label']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(n, dataset=X,  MAX_IMGS=300):\n    num_cols = 10\n    if n % num_cols == 0 and n <= MAX_IMGS:\n        images = dataset.iloc[:n].values.reshape(-1, 28, 28)\n        num_rows = n // num_cols\n        fig, ax = plt.subplots(num_rows, num_cols, figsize=(num_cols, num_rows))\n        for i in range(num_rows):\n            for j in range(num_cols):\n                ax[i, j].imshow(images[i * num_cols + j], cmap='gray')\n                ax[i, j].axis('off')\n        plt.show()\n    else:\n        print('Invalid number of images')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_digits(digit, dataset=X):\n    if digit in range(10):\n        digit_indices = np.where(y == digit)[0]\n        \n        for i in range(50):  # Display the first 50 images of the digit\n            plt.subplot(5, 10, i + 1)\n            imdata = dataset.iloc[digit_indices[i]].values.reshape(28, 28)\n            plt.imshow(imdata, cmap='gray')\n            plt.xticks([])\n            plt.yticks([])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_digits(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_pca(n_component, dataset):\n    X = StandardScaler().fit_transform(dataset)\n    pca = PCA(n_components=n_component)\n    x_pca = pca.fit_transform(X)\n    return pca, x_pca","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\ndef fit_forest(X, y, save = (False, 'model_digitREC'), plot =True):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n    clf = RandomForestClassifier(n_estimators=130, max_depth=None)\n    clf.fit(X_train, y_train)\n    # predictions\n    y_pred = clf.predict(X_test)\n    # scoring\n    mat = confusion_matrix(y_test, y_pred)\n    if plot:\n       plt.figure(figsize=(8,8), dpi=170)\n       sns.heatmap(mat, annot=True, linewidths=0.5, cmap='Blues',fmt='d')\n       plt.show()\n    else:\n       print(mat)\n    acc = accuracy_score(y_test, y_pred)\n    print(acc)\n    if save[0]:\n        joblib.dump(clf, f'{save[1]}.joblib')\n    return acc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 id=\"2\" style=\"color:skyblue\">Traditional Machine Learning</h1>","metadata":{}},{"cell_type":"markdown","source":"## <h2 id=\"21\" style=\"color:skyblue\">RandomForest with the whole dataset</h2>","metadata":{}},{"cell_type":"code","source":"fit_forest(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2 id=\"22\" style=\"color:skyblue\">RandomForest with the PCA reduced dim</h2>","metadata":{}},{"cell_type":"code","source":"# Reduce the features to 40 only\npca, X_pca = do_pca(40, X)\n# let's try fitting to a forest\nfit_forest(X_pca, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style=\"color:skyblue\" id=\"3\">ANN</h1>","metadata":{}},{"cell_type":"markdown","source":"![Alt text](image-1.png)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.datasets import mnist\n\nnb_classes = 10\n\n# the data, shuffled and split between tran and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nprint(\"X_train original shape\", X_train.shape)\nprint(\"y_train original shape\", y_train.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2 id=\"31\">Create Sequential Model </h2>","metadata":{}},{"cell_type":"code","source":"model = Sequential()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2 id=\"32\">Add Layers</h2>","metadata":{}},{"cell_type":"code","source":"X_train = X_train.reshape(60000, 784)\nX_test = X_test.reshape(10000, 784)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\nprint(\"Training matrix shape\", X_train.shape)\nprint(\"Testing matrix shape\", X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\n\nY_train = to_categorical(y_train, 10)\nY_test =  to_categorical(y_test, 10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.add(Dense(10, activation='sigmoid', input_shape=(784,)))\n'''\nWe explicitly express in the input_shape argument of the first layer what the input data is like:\n a tensor that indicates that we have 784 features of the model.\n\nThe tensor is being defined is (None, 784,). \n'''\nmodel.add(Dense(10, activation='softmax'))\n'''\nThe second layer is a softmax layer of 10 neurons, \nwhich means that it will return a matrix of 10 probability values representing the 10 possible digits.\n\nEach value will be the probability that the image of the current digit belongs to each one of them. \n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2 id=\"33\">Compile the model</h2>","metadata":{}},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the model summary to see the architecture\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2 id=\"34\">Train the model</h2>","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, Y_train, batch_size=100, epochs=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Alt text](image-2.png)","metadata":{}},{"cell_type":"code","source":"# model2\nmodel2 = Sequential()\nmodel2.add(Dense(512, input_shape=(784,)))\nmodel2.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n                              # of the layer above. Here, with a \"rectified linear unit\",\n                              # we clamp all values below 0 to 0.\n                           \nmodel2.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\nmodel2.add(Dense(512))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(10))\nmodel2.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n                                 # ensures the output is a valid probaility distribution, that is\n                                 # that its values are all non-negative and sum to 1.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model2.fit(X_train, Y_train,\n          batch_size=128, epochs=10, verbose=1,\n          validation_data=(X_test, Y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_test, Y_test, verbose=0)\nprint('Test accuracy:', score[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.save('mnist2.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom tkinter import *\nimport tkinter as tk\nimport win32gui\nfrom PIL import ImageGrab, Image\nimport numpy as np\nfrom PIL import ImageOps, ImageFilter\n\n\n\nmodel = load_model('mnist2.h5')\n\n\ndef predict_digit(img):\n    # Resize image to 28x28 pixels\n    img = img.resize((28, 28))\n\n    # Convert image to grayscale\n    img_gray = img.convert('L')\n\n    # Invert the grayscale image\n    inverted_image = ImageOps.invert(img_gray)\n\n    # Save the inverted image for debugging purposes\n    inverted_image.save('inverted.png')\n\n    # Convert the inverted image to a NumPy array\n    inverted_image = np.array(inverted_image)\n\n    # Reshape to support our model input and normalize\n    inverted_image = inverted_image.reshape(1, 784)\n    inverted_image = inverted_image.astype('float32')\n\n    # Predict the class\n    res = model.predict(inverted_image)\n    print(res)\n\n\n    print(np.argmax(res[0]), \" , \", max(res[0]))\n\n    return np.argmax(res[0]), max(res[0])\n\nclass App(tk.Tk):\n    def __init__(self):\n        tk.Tk.__init__(self)\n\n        self.x = self.y = 0\n        \n        # Creating elements\n        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n        self.label = tk.Label(self, text=\"Draw..\", font=(\"Helvetica\", 48))\n        self.classify_btn = tk.Button(self, text = \"Recognise\", command = self.classify_handwriting)   \n        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n       \n        # Grid structure\n        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n        self.label.grid(row=0, column=1,pady=2, padx=2)\n        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n        self.button_clear.grid(row=1, column=0, pady=2)\n        \n        #self.canvas.bind(\"<Motion>\", self.start_pos)\n        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n\n    def clear_all(self):\n        self.canvas.delete(\"all\")\n        \n    def classify_handwriting(self):\n        HWND = self.canvas.winfo_id()  # get the handle of the canvas\n        rect = win32gui.GetWindowRect(HWND)  # get the coordinate of the canvas\n        a,b,c,d = rect\n        rect=(a+4,b+4,c-4,d-4)\n        im = ImageGrab.grab(rect)\n\n        # Predict the input image\n        digit, acc = predict_digit(im)\n\n        # Display the prediction results on the GUI\n        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n        \n\n    def draw_lines(self, event):\n        self.x = event.x\n        self.y = event.y\n        r=8\n        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n       \napp = App()\nmainloop()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom tkinter import *\nimport tkinter as tk\nimport win32gui\nfrom PIL import ImageGrab, Image, ImageTk\nimport numpy as np\nfrom PIL import ImageOps\n\nmodel = load_model('mnist2.h5')\n\ndef predict_digit(img):\n    # Resize image to 28x28 pixels\n    img = img.resize((28, 28))\n\n    # Convert image to grayscale\n    img_gray = img.convert('L')\n\n    # Invert the grayscale image\n    inverted_image = ImageOps.invert(img_gray)\n\n    # Save the inverted image for debugging purposes\n    inverted_image.save('inverted.png')\n\n    # Convert the inverted image to a NumPy array\n    inverted_image = np.array(inverted_image)\n\n    # Reshape to support our model input and normalize\n    inverted_image = inverted_image.reshape(1, 784)\n    inverted_image = inverted_image.astype('float32')\n\n    # Predict the class\n    res = model.predict(inverted_image)\n    print(res)\n\n\n    print(np.argmax(res[0]), \" , \", max(res[0]))\n\n    return np.argmax(res[0]), max(res[0])\nclass App(tk.Tk):\n    def __init__(self):\n        tk.Tk.__init__(self)\n\n        self.x = self.y = 0\n\n        # Creating elements\n        self.canvas = tk.Canvas(self, width=300, height=300, bg=\"white\", cursor=\"cross\")\n        self.label = tk.Label(self, text=\"Draw..\", font=(\"Helvetica\", 48))\n        self.classify_btn = tk.Button(self, text=\"Recognise\", command=self.classify_handwriting)\n        self.button_clear = tk.Button(self, text=\"Clear\", command=self.clear_all)\n\n        # Grid structure\n        self.canvas.grid(row=0, column=0, pady=2, sticky=W)\n        self.label.grid(row=0, column=1, pady=2, padx=2)\n        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n        self.button_clear.grid(row=1, column=0, pady=2)\n\n        # Bindings\n        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n\n    def clear_all(self):\n        self.canvas.delete(\"all\")\n\n    def classify_handwriting(self):\n        HWND = self.canvas.winfo_id()\n        rect = win32gui.GetWindowRect(HWND)\n        a, b, c, d = rect\n        rect = (a + 4, b + 4, c - 4, d - 4)\n        im = ImageGrab.grab(rect)\n\n        # Predict the input image\n        digit, acc = predict_digit(im)\n\n        # Display the prediction results on the GUI\n        self.label.configure(text=str(digit) + ', ' + str(int(acc * 100)) + '%')\n\n        # Show the prediction image in a separate window\n        im.show()\n\n    def draw_lines(self, event):\n        self.x = event.x\n        self.y = event.y\n        r = 8\n        self.canvas.create_oval(self.x - r, self.y - r, self.x + r, self.y + r, fill='black')\n\n\napp = App()\nmainloop()\n\n\n","metadata":{},"execution_count":null,"outputs":[]}]}